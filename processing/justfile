set dotenv-load

# Show help
default: help
help:
    @just --list --unsorted

# ==== variables ====
PROJECT_ROOT := `dirname $(pwd)`
PY_FILES := `fd --extension py --type file .  | tr '\n' ' '`

# ==== codebase ====

# sanity
[group('codebase')]
sanity:
    #!/bin/bash
    echo "PROJECT_ROOT: {{PROJECT_ROOT}}"
    echo "PY_FILES: {{PY_FILES}}"
    echo "\$ACCOUNT_CODE: ${ACCOUNT_CODE}"
    uv run scripts/sanity.py

# ruff format and ruff check
[group('codebase')]
ruff:
    @echo "{{PY_FILES}}" | xargs uv run ruff format
    @echo "{{PY_FILES}}" | xargs uv run ruff check --fix

# Lint using ty check
[group('codebase')]
ty:
    uv run ty check

# Run unit tests
[group('codebase')]
test:
    uv run pytest tests/ -v

# run all quality checks
[group('codebase')]
check: ruff ty test

# ==== main-processing ====

# Preprocess trait data for embedding generation
[group('main-processing')]
preprocess-traits:
    uv run scripts/main-processing/preprocess-traits.py

# Preprocess EFO ontology data for embedding generation
[group('main-processing')]
preprocess-efo:
    uv run scripts/main-processing/preprocess-efo.py

# Submit HPC batch job to generate trait embeddings
[group('main-processing'), group('hpc')]
embed-traits:
    sbatch --account=${ACCOUNT_CODE} scripts/bc4/embed-traits.sbatch

# Submit HPC batch job to generate EFO embeddings
[group('main-processing'), group('hpc')]
embed-efo:
    sbatch --account=${ACCOUNT_CODE} scripts/bc4/embed-efo.sbatch

# Aggregate embedding results from HPC batch jobs
[group('main-processing')]
aggregate-embeddings:
    #!/bin/bash
    # NOTE: note about the hardcoded path with hpc experiements
    TRAIT_EXPERIMENT_ID="bc4-12790166"
    EFO_EXPERIMENT_ID="bc4-12432782"
    uv run scripts/main-processing/aggregate-embeddings.py \
        --trait-results-dir {{PROJECT_ROOT}}/data/output/${TRAIT_EXPERIMENT_ID}/results \
        --efo-results-dir {{PROJECT_ROOT}}/data/output/${EFO_EXPERIMENT_ID}/results

# ==== main database ====

# Build main vector store database with embeddings and model results
[group('main-database')]
build-main-db:
    uv run scripts/main-db/build-main-database.py \
        -db vector_store \
        --force-write

# ==== trait profile similarity database ====

# Submit HPC batch job to compute pairwise trait similarities
[group('trait-profile'), group('hpc')]
compute-trait-similarities:
    sbatch --account=${ACCOUNT_CODE} scripts/bc4/compute-trait-similarity.sbatch

# Aggregate trait similarity results from HPC batch jobs
[group('trait-profile')]
aggregate-trait-similarities:
    #!/bin/bash
    # NOTE: note about the hardcoded path with hpc experiement
    EXPERIMENT_ID="bc4-12790944"
    uv run scripts/trait-profile/aggregate-trait-similarities.py \
        --input-dir {{PROJECT_ROOT}}/data/output/${EXPERIMENT_ID}/results

# Build trait profile database with similarity data
[group('trait-profile')]
build-trait-profile-db:
    uv run scripts/trait-profile/build-trait-profile-database.py \
        -db trait_profile_db \
        --memory-limit 8GB \
        --force-write

# ==== evidence profile similarity ====

# Preprocess evidence profiles from model results
[group('evidence-profile')]
preprocess-evidence-profiles:
    uv run scripts/evidence-profile/preprocess-evidence-profiles.py

# Submit HPC batch job to compute evidence similarities (lite)
[group('evidence-profile'), group('hpc')]
compute-evidence-similarities-lite:
    sbatch --account=${ACCOUNT_CODE} scripts/bc4/compute-evidence-similarity-lite.sbatch

# Submit HPC batch job to compute evidence similarities
[group('evidence-profile'), group('hpc')]
compute-evidence-similarities:
    sbatch --account=${ACCOUNT_CODE} scripts/bc4/compute-evidence-similarity.sbatch

# Aggregate evidence similarity results from HPC batch jobs
[group('evidence-profile')]
aggregate-evidence-similarities:
    #!/bin/bash
    # NOTE: Update EXPERIMENT_ID after job completion
    EXPERIMENT_ID="bc4-XXXXXXX"
    uv run scripts/evidence-profile/aggregate-evidence-similarities.py \
        --input-dir {{PROJECT_ROOT}}/data/output/${EXPERIMENT_ID}/results

# Build evidence profile database
[group('evidence-profile')]
build-evidence-profile-db:
    uv run scripts/evidence-profile/build-evidence-profile-database.py \
        -db evidence_profile_db \
        --memory-limit 8GB \
        --force-write

# Analyze evidence similarity patterns
[group('evidence-profile')]
analyze-evidence-similarity:
    uv run scripts/evidence-profile/analyze-evidence-similarity.py

# Generate summary statistics and distributions for evidence similarities
[group('evidence-profile'), group('analysis')]
analyze-evidence-summary-stats:
    uv run scripts/analysis/analyze-evidence-summary-stats.py \
        --evidence-db {{PROJECT_ROOT}}/data/db/evidence_profile_db.db \
        --output-dir {{PROJECT_ROOT}}/data/processed/evidence-profiles/analysis

# Compare evidence-based and trait-based similarities
[group('evidence-profile'), group('analysis')]
analyze-evidence-trait-comparison:
    uv run scripts/analysis/analyze-evidence-trait-comparison.py \
        --evidence-db {{PROJECT_ROOT}}/data/db/evidence_profile_db.db \
        --trait-db {{PROJECT_ROOT}}/data/db/trait_profile_db.db \
        --output-dir {{PROJECT_ROOT}}/data/processed/evidence-profiles/analysis

# Assess data quality and completeness of evidence profiles
[group('evidence-profile'), group('analysis')]
analyze-evidence-data-quality:
    uv run scripts/analysis/analyze-evidence-data-quality.py \
        --evidence-db {{PROJECT_ROOT}}/data/db/evidence_profile_db.db \
        --output-dir {{PROJECT_ROOT}}/data/processed/evidence-profiles/analysis

# Validate evidence similarity computation
[group('evidence-profile'), group('analysis')]
analyze-evidence-validation:
    uv run scripts/analysis/analyze-evidence-validation.py \
        --evidence-db {{PROJECT_ROOT}}/data/db/evidence_profile_db.db \
        --output-dir {{PROJECT_ROOT}}/data/processed/evidence-profiles/analysis \
        --top-n 100

# Run all evidence profile analysis scripts
[group('evidence-profile'), group('analysis')]
analyze-evidence-profile: analyze-evidence-summary-stats analyze-evidence-trait-comparison analyze-evidence-data-quality analyze-evidence-validation

# ==== postprocessing ====

# Generate database schema documentation
[group('postprocessing')]
generate-schema-docs:
    uv run python scripts/postprocessing/generate-schema-docs.py
