set dotenv-load

# Show help
default: help
help:
    @just --list --unsorted

# ==== variables ====
PROJECT_ROOT := `dirname $(pwd)`
PY_FILES := `fd --extension py --type file .  | tr '\n' ' '`

# ==== codebase ====

# sanity
[group('codebase')]
sanity:
    #!/bin/bash
    echo "PROJECT_ROOT: {{PROJECT_ROOT}}"
    echo "PY_FILES: {{PY_FILES}}"
    echo "\$ACCOUNT_CODE: ${ACCOUNT_CODE}"
    uv run scripts/sanity.py

# ruff format and ruff check
[group('codebase')]
ruff:
    @echo "{{PY_FILES}}" | xargs uv run ruff format
    @echo "{{PY_FILES}}" | xargs uv run ruff check --fix

# Lint using ty check
[group('codebase')]
ty:
    uv run ty check

# Run unit tests
[group('codebase')]
test:
    uv run pytest tests/ -v

# run all quality checks
[group('codebase')]
check: ruff ty test

# ==== main-processing ====

# Preprocess trait data for embedding generation
[group('main-processing')]
preprocess-traits:
    uv run scripts/main-processing/preprocess-traits.py

# Preprocess EFO ontology data for embedding generation
[group('main-processing')]
preprocess-efo:
    uv run scripts/main-processing/preprocess-efo.py

# Submit HPC batch job to generate trait embeddings
[group('main-processing'), group('hpc')]
embed-traits:
    sbatch --account=${ACCOUNT_CODE} scripts/bc4/embed-traits.sbatch

# Submit HPC batch job to generate EFO embeddings
[group('main-processing'), group('hpc')]
embed-efo:
    sbatch --account=${ACCOUNT_CODE} scripts/bc4/embed-efo.sbatch

# Aggregate embedding results from HPC batch jobs
[group('main-processing')]
aggregate-embeddings:
    #!/bin/bash
    # NOTE: note about the hardcoded path with hpc experiements
    TRAIT_EXPERIMENT_ID="bc4-12790166"
    EFO_EXPERIMENT_ID="bc4-12432782"
    uv run scripts/main-processing/aggregate-embeddings.py \
        --trait-results-dir {{PROJECT_ROOT}}/data/output/${TRAIT_EXPERIMENT_ID}/results \
        --efo-results-dir {{PROJECT_ROOT}}/data/output/${EFO_EXPERIMENT_ID}/results

# ==== main database ====

# Build main vector store database with embeddings and model results
[group('main-database')]
build-main-db:
    uv run scripts/main-db/build-main-database.py \
        -db vector_store \
        --force-write

# ==== trait profile similarity database ====

# Submit HPC batch job to compute pairwise trait similarities
[group('trait-profile'), group('hpc')]
compute-trait-similarities:
    sbatch --account=${ACCOUNT_CODE} scripts/bc4/compute-trait-similarity.sbatch

# Aggregate trait similarity results from HPC batch jobs
[group('trait-profile')]
aggregate-trait-similarities:
    #!/bin/bash
    # NOTE: note about the hardcoded path with hpc experiement
    EXPERIMENT_ID="bc4-12790944"
    uv run scripts/trait-profile/aggregate-trait-similarities.py \
        --input-dir {{PROJECT_ROOT}}/data/output/${EXPERIMENT_ID}/results

# Build trait profile database with similarity data
[group('trait-profile')]
build-trait-profile-db:
    uv run scripts/trait-profile/build-trait-profile-database.py \
        -db trait_profile_db \
        --memory-limit 8GB \
        --force-write

# ==== evidence profile similarity ====

# Preprocess evidence profiles from model results
[group('evidence-profile')]
preprocess-evidence-profiles:
    uv run scripts/evidence-profile/preprocess-evidence-profiles.py \
        --min-results 1 \
        --max-missing-rate 0.90

# Submit HPC batch job to compute evidence similarities (lite)
[group('evidence-profile'), group('hpc')]
compute-evidence-similarities-lite:
    sbatch --account=${ACCOUNT_CODE} scripts/bc4/compute-evidence-similarity-lite.sbatch

# Submit HPC batch job to compute evidence similarities
[group('evidence-profile'), group('hpc')]
compute-evidence-similarities:
    sbatch --account=${ACCOUNT_CODE} scripts/bc4/compute-evidence-similarity.sbatch

# Aggregate evidence similarity results from HPC batch jobs
[group('evidence-profile')]
aggregate-evidence-similarities:
    #!/bin/bash
    # NOTE: Update EXPERIMENT_ID after job completion
    EXPERIMENT_ID="bc4-12799903"
    uv run scripts/evidence-profile/aggregate-evidence-similarities.py \
        --input-dir {{PROJECT_ROOT}}/data/output/${EXPERIMENT_ID}/results

# Build evidence profile database
[group('evidence-profile')]
build-evidence-profile-db:
    uv run scripts/evidence-profile/build-evidence-profile-database.py \
        -db evidence_profile_db \
        --memory-limit 8GB \
        --force-write

# ==== postprocessing ====

# Generate database schema documentation
[group('postprocessing')]
generate-schema-docs:
    uv run python scripts/postprocessing/generate-schema-docs.py

# ==== analysis ===

# ==== summary statistics ====

# Generate overall database statistics from vector store
[group('summary-statistics')]
generate-overall-stats:
    uv run scripts/analysis/generate-overall-database-stats.py \
        --vector-db {{PROJECT_ROOT}}/data/db/vector_store.db \
        --output-dir {{PROJECT_ROOT}}/data/processed/overall-stats

# Generate trait profile similarity summary statistics
[group('summary-statistics')]
analyze-trait-summary-stats:
    uv run scripts/analysis/analyze-trait-summary-stats.py \
        --trait-db {{PROJECT_ROOT}}/data/db/trait_profile_db.db \
        --output-dir {{PROJECT_ROOT}}/data/processed/trait-profiles/analysis

# Generate manuscript-ready summary tables from all databases
[group('summary-statistics')]
generate-manuscript-tables:
    uv run scripts/analysis/generate-manuscript-summary-table.py \
        --overall-dir {{PROJECT_ROOT}}/data/processed/overall-stats \
        --trait-dir {{PROJECT_ROOT}}/data/processed/trait-profiles/analysis \
        --evidence-dir {{PROJECT_ROOT}}/data/processed/evidence-profiles/analysis \
        --output-dir {{PROJECT_ROOT}}/data/processed/manuscript-tables

# Run complete summary statistics pipeline
[group('summary-statistics')]
generate-all-summary-stats: generate-overall-stats analyze-trait-summary-stats generate-manuscript-tables

# ==== evidence profile analysis ====

# Run all evidence profile analysis scripts
[group('analysis')]
analyze-evidence-profile: analyze-evidence-summary-stats analyze-evidence-trait-comparison analyze-evidence-data-quality analyze-evidence-validation analyze-match-type-quality analyze-alternative-metrics analyze-efo-matching-failure

# Generate summary statistics and distributions for evidence similarities
[group('evidence-profile'), group('analysis')]
analyze-evidence-summary-stats:
    uv run scripts/analysis/analyze-evidence-summary-stats.py \
        --evidence-db {{PROJECT_ROOT}}/data/db/evidence_profile_db.db \
        --output-dir {{PROJECT_ROOT}}/data/processed/evidence-profiles/analysis

# Compare evidence-based and trait-based similarities
[group('evidence-profile'), group('analysis')]
analyze-evidence-trait-comparison:
    uv run scripts/analysis/analyze-evidence-trait-comparison.py \
        --evidence-db {{PROJECT_ROOT}}/data/db/evidence_profile_db.db \
        --trait-db {{PROJECT_ROOT}}/data/db/trait_profile_db.db \
        --output-dir {{PROJECT_ROOT}}/data/processed/evidence-profiles/analysis

# Assess data quality and completeness of evidence profiles
[group('evidence-profile'), group('analysis')]
analyze-evidence-data-quality:
    uv run scripts/analysis/analyze-evidence-data-quality.py \
        --evidence-db {{PROJECT_ROOT}}/data/db/evidence_profile_db.db \
        --output-dir {{PROJECT_ROOT}}/data/processed/evidence-profiles/analysis

# Validate evidence similarity computation
[group('evidence-profile'), group('analysis')]
analyze-evidence-validation:
    uv run scripts/analysis/analyze-evidence-validation.py \
        --evidence-db {{PROJECT_ROOT}}/data/db/evidence_profile_db.db \
        --output-dir {{PROJECT_ROOT}}/data/processed/evidence-profiles/analysis \
        --top-n 100

# Analyze match type quality stratification from HPC chunk files
[group('evidence-profile'), group('analysis')]
analyze-match-type-quality:
    #!/bin/bash
    EXPERIMENT_ID="bc4-12799649"
    uv run scripts/analysis/analyze-match-type-quality.py \
        --input-dir {{PROJECT_ROOT}}/data/output/${EXPERIMENT_ID}/results

# Analyze feasibility of alternative similarity metrics
[group('evidence-profile'), group('analysis')]
analyze-alternative-metrics:
    uv run scripts/evidence-profile/analyze-alternative-metrics.py \
        --evidence-db {{PROJECT_ROOT}}/data/db/evidence_profile_db.db \
        --output-dir {{PROJECT_ROOT}}/data/processed/evidence-profiles/analysis

# Investigate EFO matching performance and threshold sensitivity
[group('evidence-profile'), group('analysis')]
analyze-efo-matching-failure:
    #!/bin/bash
    EXPERIMENT_ID="bc4-12799864"
    uv run scripts/evidence-profile/analyze-efo-matching-failure.py \
        --batch-output-dir {{PROJECT_ROOT}}/data/output/${EXPERIMENT_ID}/results


# ==== case-study-cs2 ====

# Prepare trait profile co-occurrence datasets for CS2
[group('case-study-cs2')]
case-study-cs2-prepare:
    uv run scripts/analysis/case_study_2_prepare_profiles.py \
        --config {{PROJECT_ROOT}}/processing/config/case_studies.yml

# Build pleiotropy trait network and community summaries
[group('case-study-cs2')]
case-study-cs2-network:
    uv run scripts/analysis/case_study_2_network_analysis.py \
        --config {{PROJECT_ROOT}}/processing/config/case_studies.yml \
        --cooccurrence-dir {{PROJECT_ROOT}}/data/processed/case-study-cs2/cooccurrence

# Overlay trait similarity with evidence concordance metrics
[group('case-study-cs2')]
case-study-cs2-overlay:
    uv run scripts/analysis/case_study_2_concordance_overlay.py \
        --config {{PROJECT_ROOT}}/processing/config/case_studies.yml \
        --output-dir {{PROJECT_ROOT}}/data/processed/case-study-cs2/overlays \
        --figures-dir {{PROJECT_ROOT}}/data/processed/case-study-cs2/figures

# Rank hotspot traits and generate Markdown briefs
[group('case-study-cs2')]
case-study-cs2-hotspots:
    uv run scripts/analysis/case_study_2_hotspot_profiles.py \
        --config {{PROJECT_ROOT}}/processing/config/case_studies.yml \
        --network-dir {{PROJECT_ROOT}}/data/processed/case-study-cs2/network \
        --overlay-path {{PROJECT_ROOT}}/data/processed/case-study-cs2/overlays/trait_similarity_concordance.csv

# Run complete Case Study 2 pipeline
[group('case-study-cs2')]
case-study-cs2-all: case-study-cs2-prepare case-study-cs2-network case-study-cs2-overlay case-study-cs2-hotspots

# ==== case study 1: reproducibility analysis ====

# Extract multi-study trait pairs for reproducibility analysis
[group('case-study-cs1')]
case-study-cs1-extract-pairs:
    uv run scripts/analysis/case_study_1_extract_pairs.py

# Extract trait pairs using similarity expansion (Phase 3)
[group('case-study-cs1')]
case-study-cs1-extract-pairs-expanded:
    uv run scripts/analysis/case_study_1_extract_pairs_similarity_expanded.py

# Compute reproducibility metrics and stratify by tiers
[group('case-study-cs1')]
case-study-cs1-reproducibility-metrics:
    uv run scripts/analysis/case_study_1_reproducibility_metrics.py

# Fit temporal trend models for direction concordance
[group('case-study-cs1')]
case-study-cs1-temporal-model:
    uv run scripts/analysis/case_study_1_temporal_model.py

# Generate validation briefs for canonical trait pairs
[group('case-study-cs1')]
case-study-cs1-validation-examples:
    uv run scripts/analysis/case_study_1_validation_examples.py

# Generate tier distribution figure
[group('case-study-cs1')]
case-study-cs1-fig-tier:
    uv run python scripts/analysis/case_study_1_fig_tier_distribution.py

# Generate study count scatter plot with LOWESS curve
[group('case-study-cs1')]
case-study-cs1-fig-scatter:
    uv run python scripts/analysis/case_study_1_fig_study_count_scatter.py

# Generate match type stacked bar chart
[group('case-study-cs1')]
case-study-cs1-fig-match-type:
    uv run python scripts/analysis/case_study_1_fig_match_type_stacked.py

# Generate temporal era comparison figure
[group('case-study-cs1')]
case-study-cs1-fig-temporal:
    uv run python scripts/analysis/case_study_1_fig_temporal_era.py

# Generate regression diagnostics figure
[group('case-study-cs1')]
case-study-cs1-fig-diagnostics:
    uv run python scripts/analysis/case_study_1_fig_regression_diagnostics.py

# Generate concordance variance heatmap
[group('case-study-cs1')]
case-study-cs1-fig-heatmap:
    uv run python scripts/analysis/case_study_1_fig_concordance_heatmap.py

# Generate all study count visualizations
[group('case-study-cs1')]
case-study-cs1-fig-study-count:
    uv run python scripts/analysis/case_study_1_fig_study_count_visualizations.py

# Run era × category interaction analysis
[group('case-study-cs1')]
case-study-cs1-interaction-era-category:
    uv run python scripts/analysis/case_study_1_interaction_era_category.py

# Run temporal regression with era dummies
[group('case-study-cs1')]
case-study-cs1-interaction-era-dummies:
    uv run python scripts/analysis/case_study_1_interaction_era_dummies.py

# Run category × match type interaction analysis
[group('case-study-cs1')]
case-study-cs1-interaction-category-match:
    uv run python scripts/analysis/case_study_1_interaction_category_match.py

# Run all interaction analyses
[group('case-study-cs1')]
case-study-cs1-interactions: case-study-cs1-interaction-era-category case-study-cs1-interaction-era-dummies case-study-cs1-interaction-category-match

# Generate category tier distribution figure
[group('case-study-cs1')]
case-study-cs1-fig-category-tier:
    uv run python scripts/analysis/case_study_1_fig_category_tier_distribution.py

# Generate category concordance violin plot
[group('case-study-cs1')]
case-study-cs1-fig-category-concordance:
    uv run python scripts/analysis/case_study_1_fig_category_concordance_violin.py

# Evaluate temporal era definitions and sample size adequacy
[group('case-study-cs1')]
case-study-cs1-evaluate-eras:
    uv run python scripts/analysis/case_study_1_evaluate_eras.py

# Generate all Case Study 1 figures
[group('case-study-cs1')]
case-study-cs1-fig-all: case-study-cs1-fig-tier case-study-cs1-fig-scatter case-study-cs1-fig-match-type case-study-cs1-fig-temporal case-study-cs1-fig-diagnostics case-study-cs1-fig-heatmap case-study-cs1-fig-study-count case-study-cs1-fig-category-tier case-study-cs1-fig-category-concordance

# Run complete Case Study 1 pipeline
[group('case-study-cs1')]
case-study-cs1-all: case-study-cs1-extract-pairs case-study-cs1-reproducibility-metrics case-study-cs1-temporal-model case-study-cs1-validation-examples case-study-cs1-fig-all case-study-cs1-interactions case-study-cs1-evaluate-eras case-study-cs1-manuscript-tables

# Consolidate CS1 tables for manuscript
[group('case-study-cs1')]
case-study-cs1-manuscript-tables:
    uv run python scripts/analysis/consolidate_cs1_manuscript_tables.py \
        --input-dir {{PROJECT_ROOT}}/data/processed/case-study-cs1 \
        --output-dir {{PROJECT_ROOT}}/data/processed/manuscript-tables

# ==== case study 5: temporal evolution of MR evidence ====

# Prepare temporal metadata for all studies
[group('case-study-cs5')]
case-study-cs5-temporal-prep:
    cd {{PROJECT_ROOT}} && uv run --project processing python processing/scripts/analysis/case_study_5_temporal_preparation.py \
        --config {{PROJECT_ROOT}}/processing/config/case_studies.yml

# Analyze trait diversity over time and across methodological eras
[group('case-study-cs5')]
case-study-cs5-trait-diversity:
    cd {{PROJECT_ROOT}} && uv run --project processing python processing/scripts/analysis/case_study_5_trait_diversity.py \
        --config {{PROJECT_ROOT}}/processing/config/case_studies.yml

# Analyze evidence consistency patterns across eras
[group('case-study-cs5')]
case-study-cs5-evidence-consistency:
    cd {{PROJECT_ROOT}} && uv run --project processing python processing/scripts/analysis/case_study_5_evidence_consistency.py \
        --config {{PROJECT_ROOT}}/processing/config/case_studies.yml

# Analyze reporting completeness and STROBE-MR impact
[group('case-study-cs5')]
case-study-cs5-reporting-completeness:
    cd {{PROJECT_ROOT}} && uv run --project processing python processing/scripts/analysis/case_study_5_reporting_completeness.py \
        --config {{PROJECT_ROOT}}/processing/config/case_studies.yml

# Analyze fashionable trait trends and hype cycles
[group('case-study-cs5')]
case-study-cs5-fashionable-traits:
    cd {{PROJECT_ROOT}} && uv run --project processing python processing/scripts/analysis/case_study_5_fashionable_traits.py \
        --config {{PROJECT_ROOT}}/processing/config/case_studies.yml

# Analyze pleiotropy awareness and MR-PRESSO adoption
[group('case-study-cs5')]
case-study-cs5-pleiotropy-awareness:
    cd {{PROJECT_ROOT}} && uv run --project processing python processing/scripts/analysis/case_study_5_pleiotropy_awareness.py \
        --config {{PROJECT_ROOT}}/processing/config/case_studies.yml

# Analyze winner's curse effect size decline patterns
[group('case-study-cs5')]
case-study-cs5-winners-curse:
    cd {{PROJECT_ROOT}} && uv run --project processing python processing/scripts/analysis/case_study_5_winners_curse.py \
        --config {{PROJECT_ROOT}}/processing/config/case_studies.yml

# Run complete Case Study 5 pipeline
[group('case-study-cs5')]
case-study-cs5-all: case-study-cs5-temporal-prep case-study-cs5-trait-diversity case-study-cs5-evidence-consistency case-study-cs5-reporting-completeness case-study-cs5-fashionable-traits case-study-cs5-pleiotropy-awareness case-study-cs5-winners-curse case-study-cs5-manuscript-tables

# Consolidate CS5 tables for manuscript
[group('case-study-cs5')]
case-study-cs5-manuscript-tables:
    cd {{PROJECT_ROOT}} && uv run --project processing python processing/scripts/analysis/consolidate_cs5_manuscript_tables.py \
        --input-dir {{PROJECT_ROOT}}/data/processed/case-study-cs5 \
        --output-dir {{PROJECT_ROOT}}/data/processed/manuscript-tables

# ==== diagnostic and development tools ====

# Debug single PMID-model combination preprocessing
[group('diagnostic')]
debug-single-combination PMID MODEL:
    uv run scripts/evidence-profile/debug-single-combination.py {{PMID}} {{MODEL}}

# Diagnose p-value parsing and statistical consistency issues
[group('diagnostic')]
diagnose-pvalue-parsing:
    uv run scripts/evidence-profile/diagnose-pvalue-parsing.py

# Test fuzzy matching implementation
[group('diagnostic')]
test-fuzzy-matching:
    uv run scripts/evidence-profile/test-fuzzy-matching.py
