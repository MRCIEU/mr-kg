set dotenv-load

# Show help
default: help
help:
    @just --list --unsorted

# ==== variables ====
PROJECT_ROOT := `dirname $(pwd)`
PY_FILES := `fd --extension py --type file .  | tr '\n' ' '`

# ==== codebase ====

# sanity
[group('codebase')]
sanity:
    #!/bin/bash
    echo "PROJECT_ROOT: {{PROJECT_ROOT}}"
    echo "PY_FILES: {{PY_FILES}}"
    echo "\$ACCOUNT_CODE: ${ACCOUNT_CODE}"
    uv run scripts/sanity.py

# ruff format and ruff check
[group('codebase')]
ruff:
    @echo "{{PY_FILES}}" | xargs uv run ruff format
    @echo "{{PY_FILES}}" | xargs uv run ruff check --fix

# Lint using ty check
[group('codebase')]
ty:
    uv run ty check

# Run unit tests
[group('codebase')]
test:
    uv run pytest tests/ -v

# run all quality checks
[group('codebase')]
check: ruff ty test

# ==== main-processing ====

# Preprocess trait data for embedding generation
[group('main-processing')]
preprocess-traits:
    uv run scripts/main-processing/preprocess-traits.py

# Preprocess EFO ontology data for embedding generation
[group('main-processing')]
preprocess-efo:
    uv run scripts/main-processing/preprocess-efo.py

# Submit HPC batch job to generate trait embeddings
[group('main-processing'), group('hpc')]
embed-traits:
    sbatch --account=${ACCOUNT_CODE} scripts/bc4/embed-traits.sbatch

# Submit HPC batch job to generate EFO embeddings
[group('main-processing'), group('hpc')]
embed-efo:
    sbatch --account=${ACCOUNT_CODE} scripts/bc4/embed-efo.sbatch

# Aggregate embedding results from HPC batch jobs
[group('main-processing')]
aggregate-embeddings:
    #!/bin/bash
    # NOTE: note about the hardcoded path with hpc experiements
    TRAIT_EXPERIMENT_ID="bc4-12790166"
    EFO_EXPERIMENT_ID="bc4-12432782"
    uv run scripts/main-processing/aggregate-embeddings.py \
        --trait-results-dir {{PROJECT_ROOT}}/data/output/${TRAIT_EXPERIMENT_ID}/results \
        --efo-results-dir {{PROJECT_ROOT}}/data/output/${EFO_EXPERIMENT_ID}/results

# ==== main database ====

# Build main vector store database with embeddings and model results
[group('main-database')]
build-main-db:
    uv run scripts/main-db/build-main-database.py \
        -db vector_store \
        --force-write

# ==== trait profile similarity database ====

# Submit HPC batch job to compute pairwise trait similarities
[group('trait-profile'), group('hpc')]
compute-trait-similarities:
    sbatch --account=${ACCOUNT_CODE} scripts/bc4/compute-trait-similarity.sbatch

# Aggregate trait similarity results from HPC batch jobs
[group('trait-profile')]
aggregate-trait-similarities:
    #!/bin/bash
    # NOTE: note about the hardcoded path with hpc experiement
    EXPERIMENT_ID="bc4-12790944"
    uv run scripts/trait-profile/aggregate-trait-similarities.py \
        --input-dir {{PROJECT_ROOT}}/data/output/${EXPERIMENT_ID}/results

# Build trait profile database with similarity data
[group('trait-profile')]
build-trait-profile-db:
    uv run scripts/trait-profile/build-trait-profile-database.py \
        -db trait_profile_db \
        --memory-limit 8GB \
        --force-write

# ==== evidence profile similarity ====

# Preprocess evidence profiles from model results
[group('evidence-profile')]
preprocess-evidence-profiles:
    uv run scripts/evidence-profile/preprocess-evidence-profiles.py \
        --min-results 1 \
        --max-missing-rate 0.90

# Submit HPC batch job to compute evidence similarities (lite)
[group('evidence-profile'), group('hpc')]
compute-evidence-similarities-lite:
    sbatch --account=${ACCOUNT_CODE} scripts/bc4/compute-evidence-similarity-lite.sbatch

# Submit HPC batch job to compute evidence similarities
[group('evidence-profile'), group('hpc')]
compute-evidence-similarities:
    sbatch --account=${ACCOUNT_CODE} scripts/bc4/compute-evidence-similarity.sbatch

# Aggregate evidence similarity results from HPC batch jobs
[group('evidence-profile')]
aggregate-evidence-similarities:
    #!/bin/bash
    # NOTE: Update EXPERIMENT_ID after job completion
    EXPERIMENT_ID="bc4-12799903"
    uv run scripts/evidence-profile/aggregate-evidence-similarities.py \
        --input-dir {{PROJECT_ROOT}}/data/output/${EXPERIMENT_ID}/results

# Build evidence profile database
[group('evidence-profile')]
build-evidence-profile-db:
    uv run scripts/evidence-profile/build-evidence-profile-database.py \
        -db evidence_profile_db \
        --memory-limit 8GB \
        --force-write

# ==== postprocessing ====

# Generate database schema documentation
[group('postprocessing')]
generate-schema-docs:
    uv run python scripts/postprocessing/generate-schema-docs.py

# ==== analysis ===

# Run all evidence profile analysis scripts
[group('analysis')]
analyze-evidence-profile: analyze-evidence-summary-stats analyze-evidence-trait-comparison analyze-evidence-data-quality analyze-evidence-validation analyze-match-type-quality analyze-alternative-metrics analyze-efo-matching-failure

# Generate summary statistics and distributions for evidence similarities
[group('evidence-profile'), group('analysis')]
analyze-evidence-summary-stats:
    uv run scripts/analysis/analyze-evidence-summary-stats.py \
        --evidence-db {{PROJECT_ROOT}}/data/db/evidence_profile_db.db \
        --output-dir {{PROJECT_ROOT}}/data/processed/evidence-profiles/analysis

# Compare evidence-based and trait-based similarities
[group('evidence-profile'), group('analysis')]
analyze-evidence-trait-comparison:
    uv run scripts/analysis/analyze-evidence-trait-comparison.py \
        --evidence-db {{PROJECT_ROOT}}/data/db/evidence_profile_db.db \
        --trait-db {{PROJECT_ROOT}}/data/db/trait_profile_db.db \
        --output-dir {{PROJECT_ROOT}}/data/processed/evidence-profiles/analysis

# Assess data quality and completeness of evidence profiles
[group('evidence-profile'), group('analysis')]
analyze-evidence-data-quality:
    uv run scripts/analysis/analyze-evidence-data-quality.py \
        --evidence-db {{PROJECT_ROOT}}/data/db/evidence_profile_db.db \
        --output-dir {{PROJECT_ROOT}}/data/processed/evidence-profiles/analysis

# Validate evidence similarity computation
[group('evidence-profile'), group('analysis')]
analyze-evidence-validation:
    uv run scripts/analysis/analyze-evidence-validation.py \
        --evidence-db {{PROJECT_ROOT}}/data/db/evidence_profile_db.db \
        --output-dir {{PROJECT_ROOT}}/data/processed/evidence-profiles/analysis \
        --top-n 100

# Analyze match type quality stratification from HPC chunk files
[group('evidence-profile'), group('analysis')]
analyze-match-type-quality:
    #!/bin/bash
    EXPERIMENT_ID="bc4-12799649"
    uv run scripts/analysis/analyze-match-type-quality.py \
        --input-dir {{PROJECT_ROOT}}/data/output/${EXPERIMENT_ID}/results

# Analyze feasibility of alternative similarity metrics
[group('evidence-profile'), group('analysis')]
analyze-alternative-metrics:
    uv run scripts/evidence-profile/analyze-alternative-metrics.py \
        --evidence-db {{PROJECT_ROOT}}/data/db/evidence_profile_db.db \
        --output-dir {{PROJECT_ROOT}}/data/processed/evidence-profiles/analysis

# Investigate EFO matching performance and threshold sensitivity
[group('evidence-profile'), group('analysis')]
analyze-efo-matching-failure:
    #!/bin/bash
    EXPERIMENT_ID="bc4-12799864"
    uv run scripts/evidence-profile/analyze-efo-matching-failure.py \
        --batch-output-dir {{PROJECT_ROOT}}/data/output/${EXPERIMENT_ID}/results


# ==== case-study-cs2 ====

# Prepare trait profile co-occurrence datasets for CS2
[group('case-study-cs2')]
case-study-cs2-prepare:
    uv run scripts/analysis/case_study_2_prepare_profiles.py \
        --config {{PROJECT_ROOT}}/processing/config/case_studies.yml

# Build pleiotropy trait network and community summaries
[group('case-study-cs2')]
case-study-cs2-network:
    uv run scripts/analysis/case_study_2_network_analysis.py \
        --config {{PROJECT_ROOT}}/processing/config/case_studies.yml \
        --cooccurrence-dir {{PROJECT_ROOT}}/data/processed/case-study-cs2/cooccurrence

# Overlay trait similarity with evidence concordance metrics
[group('case-study-cs2')]
case-study-cs2-overlay:
    uv run scripts/analysis/case_study_2_concordance_overlay.py \
        --config {{PROJECT_ROOT}}/processing/config/case_studies.yml \
        --output-dir {{PROJECT_ROOT}}/data/processed/case-study-cs2/overlays \
        --figures-dir {{PROJECT_ROOT}}/data/processed/case-study-cs2/figures

# Rank hotspot traits and generate Markdown briefs
[group('case-study-cs2')]
case-study-cs2-hotspots:
    uv run scripts/analysis/case_study_2_hotspot_profiles.py \
        --config {{PROJECT_ROOT}}/processing/config/case_studies.yml \
        --network-dir {{PROJECT_ROOT}}/data/processed/case-study-cs2/network \
        --overlay-path {{PROJECT_ROOT}}/data/processed/case-study-cs2/overlays/trait_similarity_concordance.csv

# Run complete Case Study 2 pipeline
[group('case-study-cs2')]
case-study-cs2-all: case-study-cs2-prepare case-study-cs2-network case-study-cs2-overlay case-study-cs2-hotspots

# ==== case study 1: reproducibility analysis ====

# Extract multi-study trait pairs for reproducibility analysis
[group('case-study-cs1')]
case-study-cs1-extract-pairs:
    uv run scripts/analysis/case_study_1_extract_pairs.py

# Compute reproducibility metrics and stratify by tiers
[group('case-study-cs1')]
case-study-cs1-reproducibility-metrics:
    uv run scripts/analysis/case_study_1_reproducibility_metrics.py

# Fit temporal trend models for direction concordance
[group('case-study-cs1')]
case-study-cs1-temporal-model:
    uv run scripts/analysis/case_study_1_temporal_model.py

# Generate validation briefs for canonical trait pairs
[group('case-study-cs1')]
case-study-cs1-validation-examples:
    uv run scripts/analysis/case_study_1_validation_examples.py

# Run complete Case Study 1 pipeline
[group('case-study-cs1')]
case-study-cs1-all: case-study-cs1-extract-pairs case-study-cs1-reproducibility-metrics case-study-cs1-temporal-model case-study-cs1-validation-examples

# ==== diagnostic and development tools ====

# Debug single PMID-model combination preprocessing
[group('diagnostic')]
debug-single-combination PMID MODEL:
    uv run scripts/evidence-profile/debug-single-combination.py {{PMID}} {{MODEL}}

# Diagnose p-value parsing and statistical consistency issues
[group('diagnostic')]
diagnose-pvalue-parsing:
    uv run scripts/evidence-profile/diagnose-pvalue-parsing.py

# Test fuzzy matching implementation
[group('diagnostic')]
test-fuzzy-matching:
    uv run scripts/evidence-profile/test-fuzzy-matching.py
